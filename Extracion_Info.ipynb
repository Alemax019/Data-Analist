{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coursera = pd.read_csv(r'.\\Dataset_PI03_Data_Analyst\\Coursera_courses.csv')\n",
    "df_co_re = pd.read_csv(r'.\\Dataset_PI03_Data_Analyst\\Coursera_reviews.csv')\n",
    "df_edx = pd.read_csv(r'.\\Dataset_PI03_Data_Analyst\\edx_courses.csv')\n",
    "df_udemy = pd.read_csv(r'.\\Dataset_PI03_Data_Analyst\\udemy_courses.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracion informacion EDX #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>date_reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm currently enrolled in the 'Assessing Commu...</td>\n",
       "      <td>Jan 13, 2023</td>\n",
       "      <td>&lt;img alt=\"Rated 1 out of 5 stars\" src=\"https:/...</td>\n",
       "      <td>Assessing Community Needs for Library Managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EdX used to be a nonprofit education company s...</td>\n",
       "      <td>Dec 22, 2022</td>\n",
       "      <td>&lt;img alt=\"Rated 1 out of 5 stars\" src=\"https:/...</td>\n",
       "      <td>Low quality courses with errors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My second day in and I'm totally lost and ther...</td>\n",
       "      <td>Dec 7, 2022</td>\n",
       "      <td>&lt;img alt=\"Rated 1 out of 5 stars\" src=\"https:/...</td>\n",
       "      <td>Waste of time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I completed edX's Online Teaching and Learning...</td>\n",
       "      <td>Oct 25, 2022</td>\n",
       "      <td>&lt;img alt=\"Rated 1 out of 5 stars\" src=\"https:/...</td>\n",
       "      <td>No content and no instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the strongest possible terms, I urge you no...</td>\n",
       "      <td>Nov 23, 2022</td>\n",
       "      <td>&lt;img alt=\"Rated 1 out of 5 stars\" src=\"https:/...</td>\n",
       "      <td>ColumbiaX DS101X: Statistical Thinking for Dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  date_reviews  \\\n",
       "0  I'm currently enrolled in the 'Assessing Commu...  Jan 13, 2023   \n",
       "1  EdX used to be a nonprofit education company s...  Dec 22, 2022   \n",
       "2  My second day in and I'm totally lost and ther...   Dec 7, 2022   \n",
       "3  I completed edX's Online Teaching and Learning...  Oct 25, 2022   \n",
       "4  In the strongest possible terms, I urge you no...  Nov 23, 2022   \n",
       "\n",
       "                                              rating  \\\n",
       "0  <img alt=\"Rated 1 out of 5 stars\" src=\"https:/...   \n",
       "1  <img alt=\"Rated 1 out of 5 stars\" src=\"https:/...   \n",
       "2  <img alt=\"Rated 1 out of 5 stars\" src=\"https:/...   \n",
       "3  <img alt=\"Rated 1 out of 5 stars\" src=\"https:/...   \n",
       "4  <img alt=\"Rated 1 out of 5 stars\" src=\"https:/...   \n",
       "\n",
       "                                              course  \n",
       "0     Assessing Community Needs for Library Managers  \n",
       "1                    Low quality courses with errors  \n",
       "2                                      Waste of time  \n",
       "3                       No content and no instructor  \n",
       "4  ColumbiaX DS101X: Statistical Thinking for Dat...  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Dada la informacion otorgada por la empresa, evidenciamos que nos hace falta mas informacion para mejorar nuestro\n",
    "analisis de la infomacion para la toma de deciciones por este motivo decidimos realizar busqueda de mas informacion mediante\n",
    "web scraping una alternativa que nos permite extraer informacion de paginas web'''\n",
    "\n",
    "## Lo primero que realizamos es instanciar las listas donde se va aguardar la imformacion solicitada\n",
    "reviews = list()\n",
    "date_reviews = list()\n",
    "rating = list()\n",
    "course = list()\n",
    "\n",
    "## este contador es para poder iterar en las paginas donde se encuentra la inforcion \n",
    "count = []\n",
    "for i in range(1,50):\n",
    "    count.append(str(i))\n",
    "    for e in count:\n",
    "\n",
    "        ## Instaciamos nuestra variable url, y utilizamos la libreria requests para obtener la informacion de nuestra pagina web    \n",
    "        url = 'https://www.trustpilot.com/review/www.edx.org?page='+e\n",
    "        html = rq.get(url)\n",
    "        content = html.content\n",
    "\n",
    "        ## Mediante la libreria BeautifulSoup, nos permite leer y organizar la informacion en un archivo html, por medio\n",
    "        ## de esta libreria nos permite leer la informacion de una manera mas clara\n",
    "        soup = b(html.content, 'html.parser')\n",
    "\n",
    "        ## ponemos un nuevo contador para poder iterar en los diferentes numeros de estrallas \n",
    "        num = []\n",
    "        for i in range(1,6):\n",
    "            num.append(str(i))\n",
    "            for e in num:\n",
    "\n",
    "                ## mediante el metodo findAll podemos iterar por toda la pagina web que tenga la etiqueta instanciada\n",
    "                ## realizando la iteracion primero por las estrellas hace que toda la informacion quede organizada por el numero de \n",
    "                ## estrellas\n",
    "                star = soup.findAll('img',{'alt':\"Rated \"+e+\" out of 5 stars\"})\n",
    "                for i in star:\n",
    "                    rating.append(str(i))\n",
    "                    \n",
    "                    ## realizamos este proceso con las demas variables para obtener la informacion solicitada\n",
    "                    revw = soup.findAll('p',{'class':\"typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn\"})\n",
    "                    for i in revw:\n",
    "                        reviews.append(i.text)\n",
    "\n",
    "                    date_rews = soup.findAll('div',{'class':\"styles_reviewHeader__iU9Px\"})\n",
    "                    for i in date_rews:\n",
    "                        date_reviews.append(i.text)\n",
    "\n",
    "                    curso = soup.findAll('h2',{'class':\"typography_heading-s__f7029 typography_appearance-default__AAY17\"})\n",
    "                    for i in curso:\n",
    "                        course.append(i.text)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambios y exportacion de informacion obtenida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Los array tiene diferentes dimenciones, hacermos una normalizacion de los array para poder crear un dataframe limpio\n",
    "reviews = reviews[:22001]\n",
    "date_reviews = date_reviews[:22001]\n",
    "rating = rating[:22001]\n",
    "course = course[:22001] \n",
    "\n",
    "## Creammos un dataframe donde esta toda la informacion\n",
    "edx_reviews = pd.DataFrame({'reviews':reviews,'date_reviews':date_reviews,'rating':rating,'course':course})\n",
    "\n",
    "## le hago una transformacion a la columna rating, antes de generar el dataset\n",
    "edx_reviews2 = edx_reviews['rating'].str.split('[=\"]',expand=True)\n",
    "edx_reviews2.drop(columns=[0,1,3,4,5,6], inplace=True)\n",
    "edx_reviews.drop(['rating'], axis=1, inplace=True)\n",
    "edx_reviews['rating'] = edx_reviews2[2]\n",
    "edx_reviews.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "## Exporto el csv para no volver a ejecutar todo el codigo ya que se demora aproximadamente 60 minutos\n",
    "edx_reviews.to_csv('edx_reviews.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracion informacion udemy #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list()\n",
    "date_reviews = list()\n",
    "rating = list()\n",
    "course = list()\n",
    "count = []\n",
    "for i in range(1,50):\n",
    "    count.append(str(i))\n",
    "    for e in count:\n",
    "            \n",
    "        url = 'https://www.trustpilot.com/review/udemy.com?page='+e\n",
    "        html = rq.get(url)\n",
    "        content = html.content\n",
    "        soup = b(html.content, 'html.parser')\n",
    "\n",
    "        num = []\n",
    "        for i in range(1,6):\n",
    "            num.append(str(i))\n",
    "            for e in num:\n",
    "                star = soup.findAll('img',{'alt':\"Rated \"+e+\" out of 5 stars\"})\n",
    "                for i in star:\n",
    "                    rating.append(str(i))\n",
    "\n",
    "                    revw = soup.findAll('p',{'class':\"typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn\"})\n",
    "                    for i in revw:\n",
    "                        reviews.append(i.text)\n",
    "\n",
    "                    date_rews = soup.findAll('div',{'class':\"styles_reviewHeader__iU9Px\"})\n",
    "                    for i in date_rews:\n",
    "                        date_reviews.append(i.text)\n",
    "\n",
    "                    curso = soup.findAll('h2',{'class':\"typography_heading-s__f7029 typography_appearance-default__AAY17\"})\n",
    "                    for i in curso:\n",
    "                        course.append(i.text)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambios informacion obtenida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[:22001]\n",
    "date_reviews = date_reviews[:22001]\n",
    "rating = rating[:22001]\n",
    "course = course[:22001] \n",
    "\n",
    "edx_reviews = pd.DataFrame({'reviews':reviews,'date_reviews':date_reviews,'rating':rating,'course':course})\n",
    "edx_reviews.head()\n",
    "edx_reviews2 = edx_reviews['rating'].str.split('[=\"]',expand=True)\n",
    "edx_reviews2.drop(columns=[0,1,3,4,5,6], inplace=True)\n",
    "edx_reviews.drop(['rating'], axis=1, inplace=True)\n",
    "edx_reviews['rating'] = edx_reviews2[2]\n",
    "edx_reviews.to_csv('./Dataset_PI03_Data_Analyst/udemy_reviews.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracion info udemy #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dada la informacion otorgada por la empresa, evidenciamos que nos hace falta mas informacion para mejorar nuestro\n",
    "analisis de la infomacion para la toma de deciciones por este motivo decidimos realizar busqueda de mas informacion mediante\n",
    "web scraping una alternativa que nos permite extraer informacion de paginas web'''\n",
    "\n",
    "## Lo primero que realizamos es instanciar las listas donde se va aguardar la imformacion solicitada\n",
    "reviews3 = list()\n",
    "date_reviews3 = list()\n",
    "rating3 = list()\n",
    "\n",
    "## este contador es para poder iterar en las paginas donde se encuentra la inforcion \n",
    "count = []\n",
    "for i in range(1,6):\n",
    "    count.append(str(i))\n",
    "    for e in count:\n",
    "\n",
    "        ## Instaciamos nuestra variable url, y utilizamos la libreria requests para obtener la informacion de nuestra pagina web    \n",
    "        url = 'https://www.consumeraffairs.com/education/online-courses/udemy.html?page='+e\n",
    "        html = rq.get(url)\n",
    "        content = html.content\n",
    "\n",
    "        ## Mediante la libreria BeautifulSoup, nos permite leer y organizar la informacion en un archivo html, por medio\n",
    "        ## de esta libreria nos permite leer la informacion de una manera mas clara\n",
    "        soup = b(html.content, 'html.parser')\n",
    "\n",
    "        ## ponemos un nuevo contador para poder iterar en los diferentes numeros de estrallas \n",
    "        num = []\n",
    "        for i in range(1,6):\n",
    "            num.append(str(i))\n",
    "            for e in num:\n",
    "\n",
    "                ## mediante el metodo findAll podemos iterar por toda la pagina web que tenga la etiqueta instanciada\n",
    "                ## realizando la iteracion primero por las estrellas hace que toda la informacion quede organizada por el numero de \n",
    "                ## estrellas\n",
    "                star = soup.findAll('meta',{'itemprop':\"ratingValue\"})\n",
    "                for i in star:\n",
    "                    rating3.append(str(i))\n",
    "                    \n",
    "                ## realizamos este proceso con las demas variables para obtener la informacion solicitada\n",
    "                revw = soup.findAll('div',{'class':\"rvw-bd\"})\n",
    "                for i in revw:\n",
    "                    reviews3.append(i.text)\n",
    "\n",
    "                date_rews = soup.findAll('span',{'class':\"ca-txt-cpt\"})\n",
    "                for i in date_rews:\n",
    "                    date_reviews3.append(i.text)\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Los array tiene diferentes dimenciones, hacermos una normalizacion de los array para poder crear un dataframe limpio\n",
    "reviews = reviews3[:5001]\n",
    "date_reviews = date_reviews3[:5001]\n",
    "rating = rating3[:5001]\n",
    "\n",
    "\n",
    "## Creammos un dataframe donde esta toda la informacion\n",
    "edx_reviews = pd.DataFrame({'reviews':reviews,'date_reviews':date_reviews,'rating':rating})\n",
    "\n",
    "## le hago una transformacion a la columna rating, antes de generar el dataset\n",
    "edx_reviews2 = edx_reviews['rating'].str.split('[=\"]',expand=True)\n",
    "edx_reviews.drop(['rating'], axis=1, inplace=True)\n",
    "edx_reviews['rating'] = edx_reviews2[2]\n",
    "\n",
    "## Exporto el csv para no volver a ejecutar todo el codigo ya que se demora aproximadamente 60 minutos\n",
    "edx_reviews.to_csv('udemy_reviews_2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranformaciones coursera #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dada la informacion otorgada por la empresa, evidenciamos que nos hace falta mas informacion para mejorar nuestro\n",
    "analisis de la infomacion para la toma de deciciones por este motivo decidimos realizar busqueda de mas informacion mediante\n",
    "web scraping una alternativa que nos permite extraer informacion de paginas web'''\n",
    "\n",
    "## Lo primero que realizamos es instanciar las listas donde se va aguardar la imformacion solicitada\n",
    "reviews3 = list()\n",
    "date_reviews3 = list()\n",
    "rating3 = list()\n",
    "\n",
    "## este contador es para poder iterar en las paginas donde se encuentra la inforcion \n",
    "count = []\n",
    "for i in range(1,6):\n",
    "    count.append(str(i))\n",
    "    for e in count:\n",
    "\n",
    "        ## Instaciamos nuestra variable url, y utilizamos la libreria requests para obtener la informacion de nuestra pagina web    \n",
    "        url = 'https://www.consumeraffairs.com/education/online-courses/coursera.html?page='+e\n",
    "        html = rq.get(url)\n",
    "        content = html.content\n",
    "\n",
    "        ## Mediante la libreria BeautifulSoup, nos permite leer y organizar la informacion en un archivo html, por medio\n",
    "        ## de esta libreria nos permite leer la informacion de una manera mas clara\n",
    "        soup = b(html.content, 'html.parser')\n",
    "\n",
    "        ## ponemos un nuevo contador para poder iterar en los diferentes numeros de estrallas \n",
    "        num = []\n",
    "        for i in range(1,6):\n",
    "            num.append(str(i))\n",
    "            for e in num:\n",
    "\n",
    "                ## mediante el metodo findAll podemos iterar por toda la pagina web que tenga la etiqueta instanciada\n",
    "                ## realizando la iteracion primero por las estrellas hace que toda la informacion quede organizada por el numero de \n",
    "                ## estrellas\n",
    "                star = soup.findAll('meta',{'itemprop':\"ratingValue\"})\n",
    "                for i in star:\n",
    "                    rating3.append(str(i))\n",
    "                    \n",
    "                ## realizamos este proceso con las demas variables para obtener la informacion solicitada\n",
    "                revw = soup.findAll('div',{'class':\"rvw-bd\"})\n",
    "                for i in revw:\n",
    "                    reviews3.append(i.text)\n",
    "\n",
    "                date_rews = soup.findAll('span',{'class':\"ca-txt-cpt\"})\n",
    "                for i in date_rews:\n",
    "                    date_reviews3.append(i.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Los array tiene diferentes dimenciones, hacermos una normalizacion de los array para poder crear un dataframe limpio\n",
    "reviews = reviews3[:5001]\n",
    "date_reviews = date_reviews3[:5001]\n",
    "rating = rating3[:5001]\n",
    "\n",
    "## Creammos un dataframe donde esta toda la informacion\n",
    "edx_reviews = pd.DataFrame({'reviews':reviews,'date_reviews':date_reviews,'rating':rating})\n",
    "\n",
    "## le hago una transformacion a la columna rating, antes de generar el dataset\n",
    "edx_reviews2 = edx_reviews['rating'].str.split('[=\"]',expand=True)\n",
    "edx_reviews.drop(['rating'], axis=1, inplace=True)\n",
    "edx_reviews['rating'] = edx_reviews2[2]\n",
    "\n",
    "## Exporto el csv para no volver a ejecutar todo el codigo ya que se demora aproximadamente 60 minutos\n",
    "edx_reviews.to_csv('./Dataset_PI03_Data_Analyst/coursera_reviews_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coursera_r[coursera_r.duplicated(subset=['reviews', 'reviewers', 'course_id'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2cebceb6c68f4ea04f0cb4e6546cfb3722fb6cf73137fe815b750b1ee1a9c58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
