# Data_Analyst
## Tabla de contenido
1. [Informacion Ganeral](#informacion-general)
2. [Tecnologia](#tecnologia)
3. [Paso a Paso](#paso-a-paso)
3. [Colaboraciones](#colaboraciones)
4. [FAQs](#faqs)
### Información General
***
Para este proyecto de Data analyst nos propusieron buscar información sobre cursos virtuales bajo las plataformas Coursera, udemy y edx, la importancia este proyecto es validar la importancia de las plataformas online para la realización de cursos o estudios para esto nos entregaron Data sets con información correspondiente a estas plataformas



## Tecnologias
***
Una Lista de las tecnologias utilizadas:
* [Python](https://example.com): Version 3.10
* [Pandas](https://example.com): Version 1.5
* [Numpy](https://example.com): Version 1.24
* [Poewr BI]
* [Requests]
* [seaborn](https://example.com): Version 0.12.2
* [matplotlib](https://example.com): Version 0.1.6

[Image text](https://github.com/Alemax019/Machine_Learning/blob/main/1_2aGjVH9aCRSXsMg1vT4peg.png)

## Paso a Paso
***
Realizaremos una breve descripción del paso a paso que realizamos para poder llegar a nuestro modelo predictivo

### Realizamos exploración 
Lo primero que debemos hacer es una exploración inicial de nuestros datos para mirar cómo se encuentra el Dataset, después de hacer una breve introducción al Dataset y verificar nuestra información pasaremos tomaremos las mejores decisiones para los procesos a realizar.

después de revisar detalladamente la información pudimos concluir que hacía falta información para desarrollar un modelo de análisis objetivo para esto realice una búsqueda de información reviews o comentarios de los cursos y plataformas del cual vamos a hacer nuestro análisis bajo esta primicia decidimos descargar o bajar información

### Transformaciones inicialies

bajo un método de web scraping el cual pudimos descargar información relevante a fechas de las reviews comentarios y puntuaciones de los cursos y plataformas decidimos validar después de esto realizamos transformaciones de la información para poder tomar mejores decisiones

Después procederemos a realizar una verificación de outliers y datos atipicos para visualizar si hay valores por fuera de los rangos previstos o que necesitemos validar.

### Normalizaciones

Hicimos un proceso adicional de validar las palabras más frecuentes de los comentarios teniendo como primicia la calificación qué otorgaron a los cursos o a las plataformas con el fin de tener un lenguaje natural sobre las calificaciones de cada puntuación después de esto culminamos con extraer y transformar los datos propuestos y unificar los en uno solo con el fin de tener una mejor performans el modelo de análisis de datos

realizamos transformaciones en power bi hay para poder concluir nuestro desarrollo del dashboard toda esta información se puede visualizar en nuestro github con un link propuesto en Google drive de los Data set ya que son muy pesados para poderlo subir a la plataforma quedamos atentos a cualquier comentario o sugerencia con el fin de seguir mejorando muchas gracias

En [Analisis_Datos](https://github.com/Alemax019/Data_Analyst/blob/main/EDA_Data_Analyst.ipynb) y [Extracción_data](https://github.com/Alemax019/Data_Analyst/blob/main/Extracion_Info.ipynb) estará más detallado todo el proceso

## Colaboraciones
***
Agradecimiento a nuestros instructores y compañeros que nos aportan deferentes ideas y conocimientos para continuar con nuestro proceso

## FAQs

Todo nuestro proyecto se encuentra en 
* Git link(https://github.com/Alemax019/Data_Analyst)
* Google Drive(https://drive.google.com/drive/folders/1cArlW087WOuUAHjqVpC8HMOjtkEquTra?usp=share_link)

Contacto:  <a href="https://www.linkedin.com/in/alemax019/"><img alt="Linkedin" src="https://img.shields.io/badge/Linkedin-0077B5?style=flat&logo=linkedin&logoColor=white"></a>  

Saludos!
